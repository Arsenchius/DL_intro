{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Введение в глубинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Домашнее задание 2. Классификация изображений. Сверточные нейронные сети.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 07.11.2021\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 28.11.2021\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 02.12.2021\n",
        "\n",
        "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 8.5, а если сдать перед самым жестким дедлайном, то ваш максимум — 5.22 балла.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=0).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "## Задание 1. (Максимум 10 баллов + 5 бонусных баллов)\n",
        "\n",
        "__Необходимо выполнить любое из двух заданий (на выбор)__\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров). Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 45 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LKcSNj4tlRVK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm_notebook\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llye3TAn9YOe",
        "outputId": "152d6baa-3b80-4467-a784-21e261b37651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-05 16:30:28--  https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/33l8lp62rmvtx40/dataset.zip [following]\n",
            "--2021-12-05 16:30:29--  https://www.dropbox.com/s/dl/33l8lp62rmvtx40/dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com/cd/0/get/BbRKT0ifSyMEcOd6qK2NyICg5l5IcBWd-Y7_TPJBGsb3ltuFM8-zHMl2A3HxgvcnmiTQ1IKH3yHM0fqodVZv_vnDenHZp7DUHQep3XIO1PfCR5iTPNgIvImw0WxLnwqVgeg1V6GJeMr2H20e_L_wCMnn/file?dl=1# [following]\n",
            "--2021-12-05 16:30:29--  https://uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com/cd/0/get/BbRKT0ifSyMEcOd6qK2NyICg5l5IcBWd-Y7_TPJBGsb3ltuFM8-zHMl2A3HxgvcnmiTQ1IKH3yHM0fqodVZv_vnDenHZp7DUHQep3XIO1PfCR5iTPNgIvImw0WxLnwqVgeg1V6GJeMr2H20e_L_wCMnn/file?dl=1\n",
            "Resolving uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com (uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com (uc614d4fa2e28fc4441da0e69ef6.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220318689 (210M) [application/binary]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 210.11M   119MB/s    in 1.8s    \n",
            "\n",
            "2021-12-05 16:30:31 (119 MB/s) - ‘dataset.zip’ saved [220318689/220318689]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=1\" -O dataset.zip && unzip -q dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QEdDQtHdlRVO"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "train_transform = T.Compose([T.ToTensor()])\n",
        "val_transform = T.Compose([T.ToTensor()])\n",
        "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
        "\n",
        "train_dataset = ImageFolder(\"./dataset/dataset/train\", transform=train_transform)\n",
        "val_dataset = ImageFolder(\"./dataset/dataset/val\", transform=val_transform)\n",
        "# REPLACE ./dataset/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n",
        "# OR USE torchvision.datasets.ImageFolder INSTEAD OF MyDataset\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=500, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrg4Yj0VlRVP",
        "outputId": "c1730c19-7543-4f3b-c3c1-c0b2a51b05fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tests passed\n"
          ]
        }
      ],
      "source": [
        "# Just very simple sanity checks\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[1][1], int)\n",
        "print(\"tests passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yYG2-Cq8lRVQ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
        "    model = model.to(device).train()\n",
        "    idx = 0\n",
        "    for (images, labels) in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        preds = model(images)\n",
        "        loss = criterion(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        idx += 1\n",
        "    if scheduler is not None:\n",
        "        scheduler.step(loss)\n",
        "\n",
        "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
        "    model = model.to(device).eval()\n",
        "    predicted_classes = torch.tensor([]).to(device)\n",
        "    true_classes = torch.tensor([]).to(device)\n",
        "    nn.CrossEntropyLoss(reduction=False)\n",
        "    for images, labels in val_dataloader: \n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          preds = model(images)\n",
        "          loss = criterion(preds, labels)\n",
        "          \n",
        "        predicted_classes = torch.cat([predicted_classes, preds.argmax(dim=-1)])\n",
        "        true_classes = torch.cat([true_classes, labels])\n",
        "\n",
        "    return loss, predicted_classes, true_classes\n",
        "\n",
        "def evaluate(model, eval_dataloader, criterion, device=\"cuda:0\"):\n",
        "    cumulative_loss = 0\n",
        "    acc = 0\n",
        "    model = model.to(device).eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(eval_dataloader): \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = criterion(preds, labels)\n",
        "            cumulative_loss += loss.item()\n",
        "            acc += (preds.argmax(1) == labels).float().mean()\n",
        "    return cumulative_loss\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
        "    for epoch in range(n_epochs):\n",
        "        train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "        loss = evaluate(model, val_dataloader, criterion, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JXFJ6oS8lRVX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model = resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(512, 200)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
        "n_epochs = 10\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesoOl6BlRVY"
      },
      "source": [
        "Простой тест на проверку правильности написанного кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_LB2jn6lRVY",
        "outputId": "53ee522d-bdf1-4327-ce9c-5682e1d00eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tests passed\n"
          ]
        }
      ],
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(predicted_labels.cpu(), true_labels.cpu())\n",
        "print(\"tests passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS-LLiXUlRVY"
      },
      "source": [
        "Запустить обучение можно в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ECIzZ_RYlRVZ"
      },
      "outputs": [],
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmR-elhJlRVZ"
      },
      "source": [
        "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGH0EFalRVb",
        "outputId": "3849b4d1-7f88-4201-b689-88a35153248f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Оценка за это задание составит 7.41 баллов, если вы делали часть 1, и 0.00 баллов, если вы делали часть 2.\n"
          ]
        }
      ],
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(true_labels.cpu(), predicted_labels.cpu())\n",
        "# accuracy = 0.42\n",
        "print(f'Оценка за это задание составит {np.clip(10 * accuracy / 0.44, 0, 10):.2f} баллов,'\\\n",
        "      f' если вы делали часть 1, и {np.clip(10 * (accuracy - 0.5) / 0.34, 0, 10):.2f} баллов,'\\\n",
        "      f' если вы делали часть 2.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "## Задание 2 (0 баллов, но при невыполнении максимум за все задание — 0 баллов)\n",
        "\n",
        "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwDWp7WzxBZZ"
      },
      "source": [
        "Пишу отчет по горячим следам, я очень много времени возился с написанием функций. Возникало много проблем во время обучения. В итоге после того как все пофиксил, начал обучение, обучение продлилось довольно долго, и изначально скор был чуть хуже чем то что у меня сейчас, наверное это из-за того что я поставил маленький батч сайз изначально по 32, далее я установил размеры батчей 128 и ошибка уже стала по-лучше. Далее я попробовал поставить размеры батчей 64 и 500 и тогда результат сильно не улучшился хотя стал близок к 7,5. В итоге так как сел я делать это дз довольно поздно то я не стал накидывать сверху аугментации для улучшения оценки и оставил все как есть.\n",
        "\n",
        "Что касается архитектуры, то здесь я использовал нечто похожее на то что было на семинарах, за исключеним того что я решил использовать sсheduler сразу в train_one_epoch так как на мой взгляд это правильнее чем использовать его в train. Добавил линейный слой также для предсказания 200 классов"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "homework-02-cnn-Tokkozhin-Arsen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "max_cell_id": 35
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
